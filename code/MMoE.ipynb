{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4dac869",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "train = joblib.load('./data_and_feature/train.txt')\n",
    "val = joblib.load('./data_and_feature/val.txt')\n",
    "test = joblib.load('./data_and_feature/test.txt')\n",
    "encoder = joblib.load('./data_and_feature/encoder.txt')\n",
    "\n",
    "train_num = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb469fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "import os\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n",
    "\n",
    "from tensorflow.keras import optimizers,initializers\n",
    "from tensorflow.python.keras.initializers import glorot_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f375ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPoolLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        mask = tf.expand_dims(tf.cast(mask,tf.float32),axis = -1)\n",
    "        x = x * mask\n",
    "        return K.sum(x, axis=self.axis) / (K.sum(mask, axis=self.axis) + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46695470",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MmoeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,expert_dim,n_expert,n_task):\n",
    "        super(MmoeLayer, self).__init__()\n",
    "        self.n_task = n_task\n",
    "        self.expert_layer = [Dense(expert_dim,activation = 'relu') for i in range(n_expert)]\n",
    "        self.gate_layers = [Dense(n_expert,activation = 'softmax') for i in range(n_task)]\n",
    "    \n",
    "    def call(self,x):\n",
    "        #多个专家网络\n",
    "        E_net = [expert(x) for expert in self.expert_layer]\n",
    "        E_net = Concatenate(axis = 1)([e[:,tf.newaxis,:] for e in E_net]) #(bs,n_expert,n_dims)\n",
    "        #多个门网络\n",
    "        gate_net = [gate(x) for gate in self.gate_layers]     #n_task个(bs,n_expert)\n",
    "        \n",
    "        #每个towers等于，对应的门网络乘上所有的专家网络。\n",
    "        towers = []\n",
    "        for i in range(self.n_task):\n",
    "            g = tf.expand_dims(gate_net[i],axis = -1)  #(bs,n_expert,1)\n",
    "            _tower = tf.matmul(E_net, g,transpose_a=True)\n",
    "            towers.append(Flatten()(_tower))           #(bs,expert_dim)\n",
    "            \n",
    "        return towers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d5df4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mmoe(sparse_cols,dense_cols,sparse_max_len,embed_dim,expert_dim,\n",
    "              varlens_cols,varlens_max_len,n_expert,n_task,target = [],\n",
    "              dnn_hidden_units = (64,),dnn_reg_l2 = 1e-5,drop_rate = 0.1,\n",
    "                embedding_reg_l2 = 1e-6):\n",
    "    \n",
    "    \n",
    "    #输入部分，分为sparse,varlens,dense部分。\n",
    "    sparse_inputs = {f:Input([1],name = f) for f in sparse_cols}\n",
    "    dense_inputs = {f:Input([1],name = f) for f in dense_cols}\n",
    "    varlens_inputs = {f:Input([None,1],name = f) for f in varlens_cols}\n",
    "        \n",
    "    input_embed = {}\n",
    "    #离散特征，embedding到k维\n",
    "    for f in sparse_cols:\n",
    "        _input = sparse_inputs[f]\n",
    "        embedding = Embedding(sparse_max_len[f], embed_dim, \n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg_l2)) \n",
    "        input_embed[f] =Flatten()(embedding(_input)) #(bs,k)\n",
    "        \n",
    "    #多标签离散变量\n",
    "    for f in varlens_inputs:\n",
    "        _input = varlens_inputs[f]\n",
    "        mask = Masking(mask_value = 0).compute_mask(_input)\n",
    "        embedding = Embedding(varlens_max_len[f], embed_dim,\n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        _embed =Reshape([-1,embed_dim])(embedding(_input))\n",
    "        out_embed = MeanPoolLayer(axis=1)(_embed,mask)\n",
    "        input_embed[f] = out_embed\n",
    "        \n",
    "    input_embed.update(dense_inputs) #加入连续变量\n",
    "    input_embed = Concatenate(axis = -1)([input_embed[f] for f in input_embed])\n",
    "    for num in dnn_hidden_units:\n",
    "        input_embed = Dropout(drop_rate)(Dense(num,activation = 'relu',\n",
    "                    kernel_regularizer=regularizers.l2(dnn_reg_l2))(input_embed))\n",
    "    \n",
    "    #mmoe网络层\n",
    "    towers = MmoeLayer(expert_dim,n_expert,n_task)(input_embed)\n",
    "    outputs = [Dense(1,activation = 'sigmoid', kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                     name = f,use_bias = True)(_t) for _t,f in zip(towers,target)]\n",
    "    inputs = [sparse_inputs[f] for f in sparse_inputs]+[varlens_inputs[f] for f in varlens_inputs]\\\n",
    "                +[dense_inputs[f] for f in dense_inputs]\n",
    "    model = Model(inputs,outputs) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5fa48ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "656/656 [==============================] - 48s 67ms/step - loss: 0.2842 - read_comment_loss: 0.1012 - like_loss: 0.1002 - click_avatar_loss: 0.0427 - forward_loss: 0.0266 - read_comment_auc: 0.9093 - like_auc: 0.8144 - click_avatar_auc: 0.7556 - forward_auc: 0.7426 - val_loss: 0.2545 - val_read_comment_loss: 0.0936 - val_like_loss: 0.0897 - val_click_avatar_loss: 0.0368 - val_forward_loss: 0.0188 - val_read_comment_auc: 0.9203 - val_like_auc: 0.8326 - val_click_avatar_auc: 0.8126 - val_forward_auc: 0.7953\n",
      "Epoch 2/4\n",
      "656/656 [==============================] - 79s 121ms/step - loss: 0.2525 - read_comment_loss: 0.0906 - like_loss: 0.0897 - click_avatar_loss: 0.0358 - forward_loss: 0.0198 - read_comment_auc: 0.9343 - like_auc: 0.8605 - click_avatar_auc: 0.8378 - forward_auc: 0.8414 - val_loss: 0.2539 - val_read_comment_loss: 0.0929 - val_like_loss: 0.0892 - val_click_avatar_loss: 0.0371 - val_forward_loss: 0.0186 - val_read_comment_auc: 0.9218 - val_like_auc: 0.8352 - val_click_avatar_auc: 0.8204 - val_forward_auc: 0.8125\n",
      "Epoch 3/4\n",
      "656/656 [==============================] - 78s 119ms/step - loss: 0.2507 - read_comment_loss: 0.0896 - like_loss: 0.0888 - click_avatar_loss: 0.0351 - forward_loss: 0.0194 - read_comment_auc: 0.9369 - like_auc: 0.8656 - click_avatar_auc: 0.8482 - forward_auc: 0.8541 - val_loss: 0.2541 - val_read_comment_loss: 0.0933 - val_like_loss: 0.0892 - val_click_avatar_loss: 0.0361 - val_forward_loss: 0.0184 - val_read_comment_auc: 0.9201 - val_like_auc: 0.8361 - val_click_avatar_auc: 0.8272 - val_forward_auc: 0.8147\n",
      "Epoch 4/4\n",
      "656/656 [==============================] - 79s 120ms/step - loss: 0.2502 - read_comment_loss: 0.0891 - like_loss: 0.0883 - click_avatar_loss: 0.0348 - forward_loss: 0.0192 - read_comment_auc: 0.9385 - like_auc: 0.8678 - click_avatar_auc: 0.8537 - forward_auc: 0.8590 - val_loss: 0.2553 - val_read_comment_loss: 0.0931 - val_like_loss: 0.0894 - val_click_avatar_loss: 0.0367 - val_forward_loss: 0.0183 - val_read_comment_auc: 0.9246 - val_like_auc: 0.8338 - val_click_avatar_auc: 0.8014 - val_forward_auc: 0.8190\n"
     ]
    }
   ],
   "source": [
    "target = [\"read_comment\", \"like\", \"click_avatar\", \"forward\"]\n",
    "sparse_features = ['userid', 'feedid', 'authorid', 'bgm_song_id', 'bgm_singer_id']\n",
    "varlen_features = ['manual_tag_list','manual_keyword_list']\n",
    "dense_features = ['videoplayseconds']\n",
    "\n",
    "# 生成输入特征设置\n",
    "sparse_max_len = {f:len(encoder[f]) + 1 for f in sparse_features}\n",
    "varlens_max_len = {f:len(encoder[f]) + 1 for f in varlen_features}\n",
    "feature_names = sparse_features+varlen_features+dense_features\n",
    "\n",
    "# 构建输入数据\n",
    "train_model_input = {name: train[name] if name not in varlen_features else np.stack(train[name]) for name in feature_names } #训练模型的输入，字典类型。名称和具体值\n",
    "val_model_input = {name: val[name] if name not in varlen_features else np.stack(val[name]) for name in feature_names }\n",
    "test_model_input = {name: test[name] if name not in varlen_features else np.stack(test[name]) for name in feature_names}\n",
    "\n",
    "train_labels = [train[y].values for y in target]\n",
    "val_labels = [val[y].values for y in target]\n",
    "\n",
    "# 多余的特征删除，释放内存\n",
    "del train,val\n",
    "gc.collect()\n",
    "\n",
    "# 构建模型，训练和评估\n",
    "model = build_mmoe(sparse_features,dense_features,sparse_max_len,embed_dim = 16,expert_dim = 32,\n",
    "          n_task = 4,n_expert = 4,varlens_cols = varlen_features,varlens_max_len = varlens_max_len,\n",
    "          dnn_hidden_units = (64,64),target = target,dnn_reg_l2 = 1e-5,drop_rate = 0.1)\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(adam, loss = 'binary_crossentropy' ,metrics = [tf.keras.metrics.AUC()],)\n",
    "\n",
    "history = model.fit(train_model_input, train_labels,validation_data = (val_model_input,val_labels),\n",
    "                    batch_size=10240, epochs=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ec2c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
